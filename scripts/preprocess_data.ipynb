{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"TinyStories-train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path.cwd() / '..' / 'data' / 'raw' / dataset_name\n",
    "with open(file_path, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1922767089\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n",
      "One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the dataset\n",
    "We will use characters as tokens, just as a baseline.\n",
    "\n",
    "Note: special tokens already exist, like `<|endoftext|>`. We'll just ignore them for now, and generate infinite text.\n",
    "\n",
    "Note: there appears to be different languages, symbols, and emojis. I can recognize Chinese characters. We'll ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£§«­°´·»¿ÂÉßàáâåèéêíïñóöúāİœɪʏʙʜіғᴀᴄᴅᴇᴏᴛᴜᴡᴢ   ​‌‎‐‑‒–—―‘’‚“”„…  ‪′€™−─❤　。」一了些他但保個們兒兩分到剛又和在天奮她己巴度很恩應把整是時會獨玉田留當的童答米給自興艾莉裡這過難高ﬁﬂ️﻿，￼�𝑐🌴🌹🍌🍞🎓💖🙂🤩\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerBase:\n",
    "    def encode(self, s):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def decode(self, t):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class CharacterTokenizer(TokenizerBase):\n",
    "    def __init__(self, chars):\n",
    "        self.stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i, ch in enumerate(chars) }\n",
    "    \n",
    "    def encode(self, s):\n",
    "        return [self.stoi[c] for c in s]\n",
    "    \n",
    "    def decode(self, l):\n",
    "        return ''.join([self.itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 74, 74, 2, 85, 73, 70, 83, 70]\n",
      "Hii there\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CharacterTokenizer(chars)\n",
    "encoded = tokenizer.encode(\"Hii there\")\n",
    "print(encoded)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000]) torch.int64\n",
      "tensor([49, 79, 70,  2, 69, 66, 90, 14,  2, 66,  2, 77, 74, 85, 85, 77, 70,  2,\n",
      "        72, 74, 83, 77,  2, 79, 66, 78, 70, 69,  2, 46, 74, 77, 90,  2, 71, 80,\n",
      "        86, 79, 69,  2, 66,  2, 79, 70, 70, 69, 77, 70,  2, 74, 79,  2, 73, 70,\n",
      "        83,  2, 83, 80, 80, 78, 16,  2, 53, 73, 70,  2, 76, 79, 70, 88,  2, 74,\n",
      "        85,  2, 88, 66, 84,  2, 69, 74, 71, 71, 74, 68, 86, 77, 85,  2, 85, 80,\n",
      "         2, 81, 77, 66, 90,  2, 88, 74, 85, 73,  2, 74, 85,  2, 67, 70, 68, 66,\n",
      "        86, 84, 70,  2, 74, 85,  2, 88, 66, 84,  2, 84, 73, 66, 83, 81, 16,  2,\n",
      "        46, 74, 77, 90,  2, 88, 66, 79, 85, 70, 69,  2, 85, 80,  2, 84, 73, 66,\n",
      "        83, 70,  2, 85, 73, 70,  2, 79, 70, 70, 69, 77, 70,  2, 88, 74, 85, 73,\n",
      "         2, 73, 70, 83,  2, 78, 80, 78, 14,  2, 84, 80,  2, 84, 73, 70,  2, 68,\n",
      "        80, 86, 77, 69,  2, 84, 70, 88,  2, 66,  2, 67, 86, 85, 85, 80, 79,  2,\n",
      "        80, 79,  2, 73, 70, 83,  2, 84, 73, 74, 83, 85, 16,  1, 46, 74, 77, 90,\n",
      "         2, 88, 70, 79, 85,  2, 85, 80,  2, 73, 70, 83,  2, 78, 80, 78,  2, 66,\n",
      "        79, 69,  2, 84, 66, 74, 69, 14,  2,  4, 47, 80, 78, 14,  2, 43,  2, 71,\n",
      "        80, 86, 79, 69,  2, 85, 73, 74, 84,  2, 79, 70, 70, 69, 77, 70, 16,  2,\n",
      "        37, 66, 79,  2, 90, 80, 86,  2, 84, 73, 66, 83, 70,  2, 74, 85,  2, 88,\n",
      "        74, 85, 73,  2, 78, 70,  2, 66, 79, 69,  2, 84, 70, 88,  2, 78, 90,  2,\n",
      "        84, 73, 74, 83, 85, 33,  4,  2, 42, 70, 83,  2, 78, 80, 78,  2, 84, 78,\n",
      "        74, 77, 70, 69,  2, 66, 79, 69,  2, 84, 66, 74, 69, 14,  2,  4, 59, 70,\n",
      "        84, 14,  2, 46, 74, 77, 90, 14,  2, 88, 70,  2, 68, 66, 79,  2, 84, 73,\n",
      "        66, 83, 70,  2, 85, 73, 70,  2, 79, 70, 70, 69, 77, 70,  2, 66, 79, 69,\n",
      "         2, 71, 74, 89,  2, 90, 80, 86, 83,  2, 84, 73, 74, 83, 85, 16,  4,  1,\n",
      "        54, 80, 72, 70, 85, 73, 70, 83, 14,  2, 85, 73, 70, 90,  2, 84, 73, 66,\n",
      "        83, 70, 69,  2, 85, 73, 70,  2, 79, 70, 70, 69, 77, 70,  2, 66, 79, 69,\n",
      "         2, 84, 70, 88, 70, 69,  2, 85, 73, 70,  2, 67, 86, 85, 85, 80, 79,  2,\n",
      "        80, 79,  2, 46, 74, 77, 90,  9, 84,  2, 84, 73, 74, 83, 85, 16,  2, 43,\n",
      "        85,  2, 88, 66, 84,  2, 79, 80, 85,  2, 69, 74, 71, 71, 74, 68, 86, 77,\n",
      "        85,  2, 71, 80, 83,  2, 85, 73, 70, 78,  2, 67, 70, 68, 66, 86, 84, 70,\n",
      "         2, 85, 73, 70, 90,  2, 88, 70, 83, 70,  2, 84, 73, 66, 83, 74, 79, 72,\n",
      "         2, 66, 79, 69,  2, 73, 70, 77, 81, 74, 79, 72,  2, 70, 66, 68, 73,  2,\n",
      "        80, 85, 73, 70, 83, 16,  2, 35, 71, 85, 70, 83,  2, 85, 73, 70, 90,  2,\n",
      "        71, 74, 79, 74, 84, 73, 70, 69, 14,  2, 46, 74, 77, 90,  2, 85, 73, 66,\n",
      "        79, 76, 70, 69,  2, 73, 70, 83,  2, 78, 80, 78,  2, 71, 80, 83,  2, 84,\n",
      "        73, 66, 83, 74, 79, 72,  2, 85, 73, 70,  2, 79, 70, 70, 69, 77, 70,  2,\n",
      "        66, 79, 69,  2, 71, 74, 89, 74, 79, 72,  2, 73, 70, 83,  2, 84, 73, 74,\n",
      "        83, 85, 16,  2, 54, 73, 70, 90,  2, 67, 80, 85, 73,  2, 71, 70, 77, 85,\n",
      "         2, 73, 66, 81, 81, 90,  2, 67, 70, 68, 66, 86, 84, 70,  2, 85, 73, 70,\n",
      "        90,  2, 73, 66, 69,  2, 84, 73, 66, 83, 70, 69,  2, 66, 79, 69,  2, 88,\n",
      "        80, 83, 76, 70, 69,  2, 85, 80, 72, 70, 85, 73, 70, 83, 16,  1, 30, 93,\n",
      "        70, 79, 69, 80, 71, 85, 70, 89, 85, 93, 32,  1, 49, 79, 68, 70,  2, 86,\n",
      "        81, 80, 79,  2, 66,  2, 85, 74, 78, 70, 14,  2, 85, 73, 70, 83, 70,  2,\n",
      "        88, 66, 84,  2, 66,  2, 77, 74, 85, 85, 77, 70,  2, 68, 66, 83,  2, 79,\n",
      "        66, 78, 70, 69,  2, 36, 70, 70, 81, 16,  2, 36, 70, 70, 81,  2, 77, 80,\n",
      "        87, 70, 69,  2, 85, 80,  2, 72, 80,  2, 71, 66, 84, 85,  2, 66, 79, 69,\n",
      "         2, 81, 77, 66, 90,  2, 74, 79,  2, 85, 73, 70,  2, 84, 86, 79, 16,  2,\n",
      "        36, 70, 70, 81,  2, 88, 66, 84,  2, 66,  2, 73, 70, 66, 77, 85, 73, 90,\n",
      "         2, 68, 66, 83,  2, 67, 70, 68, 66, 86, 84, 70,  2, 73, 70,  2, 66, 77,\n",
      "        88, 66, 90, 84,  2, 73, 66, 69,  2, 72, 80, 80, 69,  2, 71, 86, 70, 77,\n",
      "        16,  2, 41, 80, 80, 69,  2, 71, 86, 70, 77,  2, 78, 66, 69, 70,  2, 36,\n",
      "        70, 70, 81,  2, 73, 66, 81, 81, 90,  2, 66, 79, 69,  2, 84, 85, 83, 80,\n",
      "        79, 72, 16,  1, 49, 79, 70,  2, 69, 66, 90, 14,  2, 36, 70, 70, 81,  2,\n",
      "        88, 66, 84,  2, 69, 83, 74, 87, 74, 79, 72,  2, 74, 79,  2, 85, 73, 70,\n",
      "         2, 81, 66, 83, 76,  2, 88, 73, 70, 79,  2, 73, 70,  2, 84, 66, 88,  2,\n",
      "        66,  2, 67, 74, 72,  2, 85, 83, 70, 70, 16,  2, 54, 73, 70,  2, 85, 83,\n",
      "        70, 70,  2, 73, 66, 69,  2, 78, 66, 79, 90,  2, 77, 70, 66, 87, 70, 84,\n",
      "         2, 85, 73, 66, 85,  2, 88, 70, 83, 70])\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor(tokenizer.encode(text[:1000]), dtype=torch.long)  # NOTE: just using first 1000 chars for now\n",
    "print(train_data.shape, train_data.dtype)\n",
    "print(train_data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, context_length, batch_size, data):\n",
    "        self.context_length = context_length\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "    \n",
    "    def get_batch(self):\n",
    "        ix = torch.randint(len(self.data) - self.context_length, (self.batch_size,))\n",
    "        x = torch.stack([self.data[i:i+self.context_length] for i in ix])\n",
    "        y = torch.stack([self.data[i+1:i+self.context_length+1] for i in ix])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[84, 73, 66, 83, 81, 16,  2, 46],\n",
      "        [87, 74, 79, 72,  2, 74, 79,  2],\n",
      "        [90,  2, 74, 79,  2, 85, 73, 70],\n",
      "        [66, 83, 70,  2, 85, 73, 70,  2]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[73, 66, 83, 81, 16,  2, 46, 74],\n",
      "        [74, 79, 72,  2, 74, 79,  2, 85],\n",
      "        [ 2, 74, 79,  2, 85, 73, 70,  2],\n",
      "        [83, 70,  2, 85, 73, 70,  2, 79]])\n",
      "----\n",
      "when input is [84] the target: 73\n",
      "when input is [84, 73] the target: 66\n",
      "when input is [84, 73, 66] the target: 83\n",
      "when input is [84, 73, 66, 83] the target: 81\n",
      "when input is [84, 73, 66, 83, 81] the target: 16\n",
      "when input is [84, 73, 66, 83, 81, 16] the target: 2\n",
      "when input is [84, 73, 66, 83, 81, 16, 2] the target: 46\n",
      "when input is [84, 73, 66, 83, 81, 16, 2, 46] the target: 74\n",
      "when input is [87] the target: 74\n",
      "when input is [87, 74] the target: 79\n",
      "when input is [87, 74, 79] the target: 72\n",
      "when input is [87, 74, 79, 72] the target: 2\n",
      "when input is [87, 74, 79, 72, 2] the target: 74\n",
      "when input is [87, 74, 79, 72, 2, 74] the target: 79\n",
      "when input is [87, 74, 79, 72, 2, 74, 79] the target: 2\n",
      "when input is [87, 74, 79, 72, 2, 74, 79, 2] the target: 85\n",
      "when input is [90] the target: 2\n",
      "when input is [90, 2] the target: 74\n",
      "when input is [90, 2, 74] the target: 79\n",
      "when input is [90, 2, 74, 79] the target: 2\n",
      "when input is [90, 2, 74, 79, 2] the target: 85\n",
      "when input is [90, 2, 74, 79, 2, 85] the target: 73\n",
      "when input is [90, 2, 74, 79, 2, 85, 73] the target: 70\n",
      "when input is [90, 2, 74, 79, 2, 85, 73, 70] the target: 2\n",
      "when input is [66] the target: 83\n",
      "when input is [66, 83] the target: 70\n",
      "when input is [66, 83, 70] the target: 2\n",
      "when input is [66, 83, 70, 2] the target: 85\n",
      "when input is [66, 83, 70, 2, 85] the target: 73\n",
      "when input is [66, 83, 70, 2, 85, 73] the target: 70\n",
      "when input is [66, 83, 70, 2, 85, 73, 70] the target: 2\n",
      "when input is [66, 83, 70, 2, 85, 73, 70, 2] the target: 79\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "dataloader = DataLoader(context_length=8, batch_size=4, data=train_data)\n",
    "xb, yb = dataloader.get_batch()\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(dataloader.batch_size):\n",
    "    for t in range(dataloader.context_length):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
